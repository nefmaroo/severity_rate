{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPcQ1BLxA4C3"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets accelerate\n",
        "!pip install sentencepiece \n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOyEhpNRE401"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm\n",
        "from accelerate import Accelerator\n",
        "from accelerate.utils import set_seed\n",
        "from torch.optim import lr_scheduler, AdamW \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers.models.deberta.modeling_deberta import ContextPooler\n",
        "from transformers import AutoTokenizer, AutoModel, AutoConfig, DataCollatorWithPadding, get_scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oPKRD_DiPPU-"
      },
      "outputs": [],
      "source": [
        "def set_all_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    set_seed(seed)\n",
        "\n",
        "set_all_seed()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kRpPFOKNhtc"
      },
      "source": [
        "Load Data\n",
        "---------\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eb9PFks_E6EC"
      },
      "outputs": [],
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"xxx\"\n",
        "os.environ['KAGGLE_KEY'] = \"xxx\"\n",
        "!kaggle competitions download -c jigsaw-toxic-severity-rating\n",
        "!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge\n",
        "!kaggle datasets download -d rajkumarl/ruddit-jigsaw-dataset\n",
        "\n",
        "!unzip /content/jigsaw-toxic-severity-rating.zip -d jigsaw-toxic-severity-rating/\n",
        "!unzip /content/jigsaw-toxic-comment-classification-challenge.zip -d jigsaw-toxic-comment-classification-challenge/\n",
        "!unzip /content/ruddit-jigsaw-dataset.zip -d ruddit-jigsaw-dataset/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FraztbuJE8F6"
      },
      "outputs": [],
      "source": [
        "hol_data_link = 'https://github.com/t-davidson/hate-speech-and-offensive-language/blob/master/data/labeled_data.csv?raw=true'\n",
        "ethos_data_link = 'https://github.com/intelligence-csd-auth-gr/Ethos-Hate-Speech-Dataset/blob/master/ethos/ethos_data/Ethos_Dataset_Binary.csv?raw=true'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ue0udwZjE9Mj"
      },
      "outputs": [],
      "source": [
        "twitter = pd.read_csv(hol_data_link, index_col = 0)\n",
        "ethos = pd.read_csv(ethos_data_link, sep = ';')\n",
        "ruddit = pd.read_csv('/content/ruddit-jigsaw-dataset/Dataset/ruddit_with_text.csv')[['txt', 'offensiveness_score']]\n",
        "toxkaggle = pd.read_csv('/content/jigsaw-toxic-comment-classification-challenge/train.csv.zip')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = pd.read_csv(\"/content/jigsaw-toxic-severity-rating/validation_data.csv\")\n",
        "pred_data = pd.read_csv(\"/content/jigsaw-toxic-severity-rating/comments_to_score.csv\")\n",
        "eval_data = pd.read_csv(\"/content/jigsaw-toxic-severity-rating/leaderboard.csv\")\n",
        "eval_data = eval_data.loc[(eval_data['left_comment_id'].isin(pred_data.comment_id)) &\n",
        "                (eval_data['right_comment_id'].isin(pred_data.comment_id))].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "Okp7EQ0feGzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l0c2ovQN76z"
      },
      "source": [
        "Data preprocessing\n",
        "---------"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adjust Twitter specific words/symbols"
      ],
      "metadata": {
        "id": "cbk0K8ipdpND"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ByrJ0Ocdkyd9"
      },
      "outputs": [],
      "source": [
        "def preprocess_tweets(tweet):\n",
        "    new_tweet = []\n",
        "    tokenizer = TweetTokenizer()\n",
        "    tweet = tokenizer.tokenize(tweet)\n",
        "    for word in tweet:\n",
        "        word = '@user' if word.startswith('@') and len(word) > 1 else word\n",
        "        word = 'http' if word.startswith('http') else word\n",
        "        new_tweet.append(word)\n",
        "    return \" \".join(new_tweet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-bGtJTzAE9wK"
      },
      "outputs": [],
      "source": [
        "twitter.loc[twitter['class'] == 2, 'class'] = 1\n",
        "twitter = twitter.rename(columns={\"tweet\": \"text\", \"class\": \"label\"})\n",
        "twitter['text'] = twitter['text'].apply(preprocess_tweets) # remove Twitter specific parts \n",
        "twitter = twitter[['text', 'label']]\n",
        "\n",
        "ethos = ethos.rename(columns={\"comment\": \"text\", \"isHate\": \"label\"})\n",
        "ethos = ethos.astype({'label': 'int32'})[['label', 'text']]\n",
        "\n",
        "ruddit = ruddit.loc[ruddit.txt != '[deleted]']\n",
        "ruddit = ruddit.loc[ruddit.txt != '[removed]']\n",
        "ruddit = ruddit.rename(columns={'txt':'text', 'offensiveness_score':'label'})\n",
        "ruddit['label'] = round((ruddit[\"label\"] + 1.) / 2., 0)\n",
        "\n",
        "toxkaggle['label'] = round(toxkaggle.loc[:,'toxic':].sum(axis=1)/6, 0)\n",
        "toxkaggle = toxkaggle.rename(columns={'comment_text':'text'})\n",
        "toxkaggle = toxkaggle[['text', 'label']]\n",
        "\n",
        "train_data = pd.concat([ruddit, twitter, ethos, toxkaggle]) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot most common words\n"
      ],
      "metadata": {
        "id": "Bo8Fi3L-dcpy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mqZABBcqE9yy"
      },
      "outputs": [],
      "source": [
        "data = \" \".join(train_data['text']).split(' ')\n",
        "fdist = nltk.FreqDist(data)\n",
        "most_common_words = pd.DataFrame(fdist.most_common(11), columns=['word', 'count'])\n",
        "most_common_words = most_common_words.loc[most_common_words.word != '']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lvaSS5MoE91Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "a3d67b96-f18b-4ebe-9dfc-5d95036f0df7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig, ax = plt.subplots(figsize=(10,8))\n",
        "sns.barplot(x=most_common_words['word'], y=most_common_words['count'], ax=ax, palette=sns.color_palette(\"hls\", 8), alpha=0.8)\n",
        "plt.tick_params(axis='both', which='major', labelsize=12)\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove stopwords"
      ],
      "metadata": {
        "id": "-COlZm9PdkMr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "J8ApY6x2E94c"
      },
      "outputs": [],
      "source": [
        "def remove_stopwords(text, stopwords):\n",
        "  text = [word for word in text.split(' ') if word.lower() not in stopwords]\n",
        "  return \" \".join(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "OP_QL1guE96s",
        "outputId": "a93c1ae0-204e-409a-cc9f-ab59b7c9e091"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  > difference average earnings men women explai...    0.0\n",
              "1            myth \"gap\" entirely based sex  person.     0.0\n",
              "3  assertion women get paid less *same* jobs, get...    0.0\n",
              "4  said OP that's they're measuring. They're meas...    0.0\n",
              "5  >Men women payed less job\\n\\nI think many peop...    0.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d824cd71-32e8-4047-baf1-e650f2c0a9cb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&gt; difference average earnings men women explai...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>myth \"gap\" entirely based sex  person.</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>assertion women get paid less *same* jobs, get...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>said OP that's they're measuring. They're meas...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>&gt;Men women payed less job\\n\\nI think many peop...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d824cd71-32e8-4047-baf1-e650f2c0a9cb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d824cd71-32e8-4047-baf1-e650f2c0a9cb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d824cd71-32e8-4047-baf1-e650f2c0a9cb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "en_stopwords = stopwords.words('english')\n",
        "train_data['text'] = train_data['text'].apply(remove_stopwords, args=(en_stopwords,))\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ratio of non-toxic/toxic comments in final train dataset"
      ],
      "metadata": {
        "id": "sZqh77-AdxRG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vi70igcFIFd",
        "outputId": "849f0630-21b9-4efa-a900-84fc5ed34644"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    163058\n",
              "1.0     28004\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train_data['label'].value_counts() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EOGp5r27N_h2"
      },
      "source": [
        "Dataset and Model classes\n",
        "---------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "9Z8LGs5awQ8y"
      },
      "outputs": [],
      "source": [
        "class ToxicRankDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_len):\n",
        "        self._data=data\n",
        "        self.tokenizer=tokenizer\n",
        "        self.max_len=max_len\n",
        "    def __len__(self):\n",
        "        return len(self._data)\n",
        "    def __getitem__(self, index):\n",
        "        tokenized = self.tokenizer(text=self._data['text'].values[index],\n",
        "                                   padding='max_length',\n",
        "                                   truncation=True,\n",
        "                                   max_length=self.max_len,\n",
        "                                   return_tensors='pt')\n",
        "        \n",
        "        if 'label' not in self._data.columns:\n",
        "          return tokenized['input_ids'].squeeze(), tokenized['attention_mask'].squeeze(), tokenized['token_type_ids'].squeeze()\n",
        "\n",
        "        target = self._data['label'].values[index]\n",
        "        return tokenized['input_ids'].squeeze(), tokenized['attention_mask'].squeeze(), tokenized['token_type_ids'].squeeze(), target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ToxicRankRoBERTa(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super(ToxicRankRoBERTa, self).__init__()\n",
        "        config = AutoConfig.from_pretrained(model_name)\n",
        "        self.model = AutoModel.from_pretrained(model_name)\n",
        "        self.classifier = nn.Linear(config.hidden_size, 1)\n",
        "  \n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "        outputs = self.model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        classification_output = outputs[1]\n",
        "        logits = self.classifier(classification_output)\n",
        "        return logits\n",
        "\n",
        "\n",
        "class ToxicRankDeBERTa(nn.Module):\n",
        "    def __init__(self, model_name):\n",
        "        super(ToxicRankDeBERTa, self).__init__()\n",
        "        config = AutoConfig.from_pretrained(model_name)\n",
        "        self.model = AutoModel.from_pretrained(model_name)\n",
        "        self.pooler = ContextPooler(config)\n",
        "        output_dim = self.pooler.output_dim\n",
        "        self.classifier = nn.Linear(output_dim, 1)\n",
        "  \n",
        "    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n",
        "        outputs = self.model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        encoder_layer = outputs[0]\n",
        "        pooled_output = self.pooler(encoder_layer)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "NigpPmZh3IlU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiqGtCN2qC1A"
      },
      "source": [
        "Training and evaluation\n",
        "---------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GvcIOWL9MRxY"
      },
      "outputs": [],
      "source": [
        "def eval(model, dataloader):\n",
        "  preds = []\n",
        "  model.eval()\n",
        "  for step, (batch_input_ids, batch_attention_mask) in enumerate(dataloader):\n",
        "    with torch.no_grad():\n",
        "              outputs = model(batch_input_ids, batch_attention_mask).view(-1)\n",
        "              predictions = outputs.sigmoid()\n",
        "              preds.append(predictions.cpu().data.numpy())\n",
        "  return np.concatenate(preds).ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "zsNhfkwPOIqV"
      },
      "outputs": [],
      "source": [
        "def inference(ranks_data, eval_data):\n",
        "    scores = []\n",
        "    ranks = pd.Series(ranks_data['rank'].values, index=ranks_data.comment_id).to_dict()\n",
        "\n",
        "    for index, row in eval_data.iterrows():\n",
        "      scores.append(ranks[row['left_comment_id']] < ranks[row['right_comment_id']])\n",
        "      \n",
        "    return np.mean(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "5swZmPbNMAEw"
      },
      "outputs": [],
      "source": [
        "def train_and_eval(config, train_data, val_data, pred_data, eval_data, roberta=False):\n",
        "\n",
        "  accelerator = Accelerator(fp16 = True)\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(config['model_name'])\n",
        "  train = ToxicRankDataset(train_data, tokenizer, config['train_max_len'])\n",
        "  \n",
        "  train_dataloader = DataLoader(dataset=train,\n",
        "                                  shuffle=True,\n",
        "                                  batch_size=config['train_batch_size'],\n",
        "                                  num_workers=config['dataloader_num_workers'],\n",
        "                                  pin_memory=True)\n",
        "\n",
        "  gradient_accumulation_steps = config['gradient_accumulation_steps']\n",
        "  num_train_epochs = config['num_train_epochs']\n",
        "\n",
        "  num_update_steps_per_epoch = math.ceil(len(train_dataloader) / gradient_accumulation_steps)\n",
        "  max_train_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "  if roberta:\n",
        "    model = ToxicRankRoBERTa(config['model_name'])\n",
        "  else:\n",
        "    model = ToxicRankDeBERTa(config['model_name'])\n",
        "\n",
        "  criterion = nn.BCEWithLogitsLoss()\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "  lr_scheduler = get_scheduler(\n",
        "        name=config['lr_scheduler_type'],\n",
        "        optimizer=optimizer,\n",
        "        num_warmup_steps=config['num_warmup_steps'],\n",
        "        num_training_steps=max_train_steps,\n",
        "    )\n",
        "\n",
        "  # Prepare everything with accelerator.\n",
        "  train_dataloader, model, optimizer, scheduler = accelerator.prepare(train_dataloader, model, optimizer, lr_scheduler)\n",
        "\n",
        "  # Recalculate total training steps as the size of the training dataloader may have changed.\n",
        "  num_update_steps_per_epoch = math.ceil(len(train_dataloader) / gradient_accumulation_steps)\n",
        "  max_train_steps = num_train_epochs * num_update_steps_per_epoch\n",
        "\n",
        "  # Training\n",
        "  completed_steps = 0\n",
        "  train_loss = []\n",
        "  progress_bar = tqdm(range(max_train_steps))\n",
        "\n",
        "  for epoch in range(num_train_epochs):\n",
        "        model.train()\n",
        "        for step, (batch_input_ids, batch_attention_mask, batch_token_type_ids, batch_target) in enumerate(train_dataloader):\n",
        "            with accelerator.autocast():\n",
        "                logits = model(batch_input_ids, batch_attention_mask, batch_token_type_ids).view(-1)\n",
        "                loss = criterion(logits, batch_target)\n",
        "\n",
        "            loss = loss / gradient_accumulation_steps\n",
        "            accelerator.backward(loss)\n",
        "\n",
        "            if step % gradient_accumulation_steps == 0 or step == len(train_dataloader) - 1:\n",
        "                optimizer.step()\n",
        "                lr_scheduler.step()\n",
        "                optimizer.zero_grad()\n",
        "                progress_bar.update(1)\n",
        "                completed_steps += 1\n",
        "\n",
        "            if completed_steps >= max_train_steps:\n",
        "                break  \n",
        "\n",
        "            train_loss.append(loss)\n",
        "\n",
        "  # Validation\n",
        "  less_toxic = val_data[['less_toxic']].rename(columns={'less_toxic':'text'})\n",
        "  more_toxic = val_data[['more_toxic']].rename(columns={'more_toxic':'text'})\n",
        "\n",
        "\n",
        "  less_toxic = ToxicRankDataset(less_toxic, tokenizer, config['val_max_len'])\n",
        "  less_toxic_dataloader = DataLoader(dataset=less_toxic,\n",
        "                                shuffle=True,\n",
        "                                batch_size=config['val_batch_size'],\n",
        "                                num_workers=config['dataloader_num_workers'],\n",
        "                                pin_memory=True)\n",
        "  \n",
        "  less_toxic_dataloader = accelerator.prepare(less_toxic_dataloader)\n",
        "  less_toxic_preds = eval(model, less_toxic_dataloader, accelerator)\n",
        "  less_toxic_preds = less_toxic_preds[:len(less_toxic_dataloader.dataset)]\n",
        "\n",
        "\n",
        "  more_toxic = ToxicRankDataset(more_toxic, tokenizer, config['val_max_len'])\n",
        "  more_toxic_dataloader = DataLoader(dataset=more_toxic,\n",
        "                                  shuffle=True,\n",
        "                                  batch_size=config['val_batch_size'],\n",
        "                                  num_workers=config['dataloader_num_workers'],\n",
        "                                  pin_memory=True)\n",
        "  \n",
        "  more_toxic_dataloader = accelerator.prepare(more_toxic_dataloader)\n",
        "  more_toxic_preds = eval(model, more_toxic_dataloader, accelerator)\n",
        "  more_toxic_preds = more_toxic_preds[:len(more_toxic_dataloader.dataset)]\n",
        "\n",
        "  val_score = np.mean(less_toxic_preds < more_toxic_preds)\n",
        "\n",
        "\n",
        "  # Evaluation\n",
        "  pred = ToxicRankDataset(pred_data, tokenizer, config['eval_max_len'])\n",
        "  pred_dataloader = DataLoader(dataset=pred,\n",
        "                                shuffle=True,\n",
        "                                batch_size=config['eval_batch_size'],\n",
        "                                num_workers=config['dataloader_num_workers'],\n",
        "                                pin_memory=True)\n",
        "  \n",
        "  pred_dataloader = accelerator.prepare(pred_dataloader)\n",
        "  preds = eval(model, pred_dataloader, accelerator)\n",
        "  preds = preds[:len(pred_dataloader.dataset)]\n",
        "\n",
        "  ranks = preds.argsort()\n",
        "  ranks_data = pd.DataFrame(data={'comment_id': pred_data['comment_id'], 'rank': ranks})\n",
        "  eval_score = inference(ranks_data, eval_data)\n",
        "\n",
        "  return train_loss, val_score, eval_score, ranks_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\"model_name\" : 'roberta-base',\n",
        "\n",
        "          \"train_max_len\": 192,\n",
        "          \"val_max_len\": 192,\n",
        "          \"eval_max_len\": 256,\n",
        "\n",
        "          \"train_batch_size\": 64,\n",
        "          \"val_batch_size\": 32,\n",
        "          \"eval_batch_size\": 16,\n",
        "\n",
        "          \"dataloader_num_workers\": 4,\n",
        "\n",
        "          \"learning_rate\": 5e-5,\n",
        "          \"num_train_epochs\": 4,\n",
        "          \"gradient_accumulation_steps\": 6,\n",
        "          \"lr_scheduler_type\": \"linear\", \n",
        "          \"num_warmup_steps\": 2,\n",
        "\n",
        "}\n",
        "\n",
        "roberta_base_train_loss, roberta_base_val_score, roberta_base_eval_score, roberta_ranks_data = train_and_eval(CONFIG, train_data, \n",
        "                                                                                          val_data, pred_data, eval_data, roberta=True)"
      ],
      "metadata": {
        "id": "AAwPzSAB_W3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\"model_name\" : 'cardiffnlp/twitter-roberta-base-hate',\n",
        "\n",
        "          \"train_max_len\": 200,\n",
        "          \"val_max_len\": 192,\n",
        "          \"eval_max_len\": 256,\n",
        "\n",
        "          \"train_batch_size\": 16,\n",
        "          \"val_batch_size\": 8,\n",
        "          \"eval_batch_size\": 8,\n",
        "\n",
        "          \"dataloader_num_workers\": 4,\n",
        "\n",
        "          \"learning_rate\": 1e-5,\n",
        "          \"num_train_epochs\": 3,\n",
        "          \"gradient_accumulation_steps\": 4,\n",
        "          \"lr_scheduler_type\": \"linear\", \n",
        "          \"num_warmup_steps\": 2,\n",
        "\n",
        "}\n",
        "\n",
        "roberta_hate_train_loss, roberta_hate_val_score, roberta_hate_eval_score = train_and_eval(CONFIG, train_data, \n",
        "                                                                                          val_data, pred_data, eval_data, roberta=True)"
      ],
      "metadata": {
        "id": "rdvZDHbs_dZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\"model_name\" : 'microsoft/deberta-base',\n",
        "\n",
        "          \"train_max_len\": 150,\n",
        "          \"val_max_len\": 200,\n",
        "          \"eval_max_len\": 200,\n",
        "\n",
        "          \"train_batch_size\": 16,\n",
        "          \"val_batch_size\": 16,\n",
        "          \"eval_batch_size\": 16,\n",
        "\n",
        "          \"dataloader_num_workers\": 4,\n",
        "\n",
        "          \"learning_rate\": 3e-5,\n",
        "          \"num_train_epochs\": 3,\n",
        "          \"gradient_accumulation_steps\": 8,\n",
        "          \"lr_scheduler_type\": \"linear\", \n",
        "          \"num_warmup_steps\": 2,\n",
        "\n",
        "}\n",
        "\n",
        "deberta_base_train_loss, deberta_base_val_score, deberta_base_eval_score, deberta_ranks_data = train_and_eval(CONFIG, train_data, \n",
        "                                                                                          val_data, pred_data, eval_data, roberta=False)"
      ],
      "metadata": {
        "id": "NJBp1klJ_d8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52zST7AzYqZX"
      },
      "outputs": [],
      "source": [
        "CONFIG = {\"model_name\" : 'Narrativaai/deberta-v3-small-finetuned-hate_speech18',\n",
        "\n",
        "          \"train_max_len\": 256,\n",
        "          \"val_max_len\": 256,\n",
        "          \"eval_max_len\": 256,\n",
        "\n",
        "          \"train_batch_size\": 32,\n",
        "          \"val_batch_size\": 16,\n",
        "          \"eval_batch_size\": 16,\n",
        "\n",
        "          \"dataloader_num_workers\": 4,\n",
        "\n",
        "          \"learning_rate\": 2e-5,\n",
        "          \"num_train_epochs\": 5,\n",
        "          \"gradient_accumulation_steps\": 2,\n",
        "          \"lr_scheduler_type\": \"linear\", \n",
        "          \"num_warmup_steps\": 2,\n",
        "\n",
        "}\n",
        "\n",
        "deberta_small_train_loss, deberta_small_val_score, deberta_small_eval_score, deberta_small_ranks_data = train_and_eval(CONFIG, train_data, \n",
        "                                                                                          val_data, pred_data, eval_data, roberta=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Копия блокнота \"Копия блокнота \"MN.ipynb\"\"",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}